
@inproceedings{jin_optimization_2022,
	title = {An {Optimization} {Algorithm} for the {Game} of {NoGo} based on {MCTS}},
	doi = {10.1109/GCRAIT55928.2022.00033},
	abstract = {The game of NoGo has been proposed in recent years. NoGo game and its related rules are firstly introduce. Then we discuss the problems exposed by the traditional MCTS algorithm at the beginning of the game, proposes an idea of creating a converse digraph and solves the shortcomings of the traditional MCTS (Monte-Carlo Tree Search) algorithm at the beginning of the game. Finally, the NoGo result between the proposed algorithm by this paper and other traditional algorithm is obtained. The experimental result show that our proposed algorithm are practical for NoGo.},
	booktitle = {2022 {Global} {Conference} on {Robotics}, {Artificial} {Intelligence} and {Information} {Technology} ({GCRAIT})},
	author = {Jin, Chenghou and Gao, Ming and Han, Yusen and Ma, Salimu},
	month = jul,
	year = {2022},
	keywords = {Algorithms, Artificial intelligence, Converse digraph, Games, Information technology, MCTS, Monte Carlo methods, Neural networks, NoGo Game, Optimization, Search problems},
	pages = {120--122},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\sande\\Zotero\\storage\\6RNN8IJJ\\stamp.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\sande\\Zotero\\storage\\MGYHZIRW\\Jin et al. - 2022 - An Optimization Algorithm for the Game of NoGo bas.pdf:application/pdf},
}

@misc{schulman_proximal_2017,
	title = {Proximal {Policy} {Optimization} {Algorithms}},
	url = {http://arxiv.org/abs/1707.06347},
	doi = {10.48550/arXiv.1707.06347},
	abstract = {We propose a new family of policy gradient methods for reinforcement learning, which alternate between sampling data through interaction with the environment, and optimizing a "surrogate" objective function using stochastic gradient ascent. Whereas standard policy gradient methods perform one gradient update per data sample, we propose a novel objective function that enables multiple epochs of minibatch updates. The new methods, which we call proximal policy optimization (PPO), have some of the benefits of trust region policy optimization (TRPO), but they are much simpler to implement, more general, and have better sample complexity (empirically). Our experiments test PPO on a collection of benchmark tasks, including simulated robotic locomotion and Atari game playing, and we show that PPO outperforms other online policy gradient methods, and overall strikes a favorable balance between sample complexity, simplicity, and wall-time.},
	urldate = {2023-07-23},
	publisher = {arXiv},
	author = {Schulman, John and Wolski, Filip and Dhariwal, Prafulla and Radford, Alec and Klimov, Oleg},
	month = aug,
	year = {2017},
	note = {arXiv:1707.06347 [cs]},
	keywords = {Computer Science - Machine Learning},
	file = {arXiv Fulltext PDF:C\:\\Users\\sande\\Zotero\\storage\\NUDDJS45\\Schulman et al. - 2017 - Proximal Policy Optimization Algorithms.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\sande\\Zotero\\storage\\X3CRBW5G\\1707.html:text/html},
}

@incollection{alpaydin_maschinelles_2022,
	title = {Maschinelles {Lernen}},
	copyright = {De Gruyter expressly reserves the right to use all content for commercial text and data mining within the meaning of Section 44b of the German Copyright Act.},
	isbn = {978-3-11-074019-6},
	url = {https://www.degruyter.com/document/doi/10.1515/9783110740196/html},
	abstract = {Maschinelles Lernen ist die künstliche Generierung von Wissen aus Erfahrung. Dieses Buch diskutiert Methoden aus den Bereichen Statistik, Mustererkennung und kombiniert die unterschiedlichen Ansätze, um effiziente Lösungen zu finden. Diese Auflage bietet ein neues Kapitel über Deep Learning und erweitert die Inhalte über mehrlagige Perzeptrone und bestärkendes Lernen. Eine neue Sektion über erzeugende gegnerische Netzwerke ist ebenfalls dabei.},
	language = {de},
	urldate = {2023-10-25},
	booktitle = {Maschinelles {Lernen}},
	publisher = {De Gruyter Oldenbourg},
	author = {Alpaydin, Ethem},
	month = jan,
	year = {2022},
	doi = {10.1515/9783110740196},
	keywords = {Deep Learning, Künstliche Intelligenz, Maschinelles Lernen, Neuronale Netze},
	file = {Full Text PDF:C\:\\Users\\sande\\Zotero\\storage\\KWBGQVY6\\Alpaydin - 2022 - Maschinelles Lernen.pdf:application/pdf},
}

@book{ris-ala_fundamentals_2023,
	address = {Cham},
	title = {Fundamentals of {Reinforcement} {Learning}},
	isbn = {978-3-031-37344-2 978-3-031-37345-9},
	url = {https://link.springer.com/10.1007/978-3-031-37345-9},
	language = {en},
	urldate = {2023-10-25},
	publisher = {Springer Nature Switzerland},
	author = {Ris-Ala, Rafael},
	year = {2023},
	doi = {10.1007/978-3-031-37345-9},
	keywords = {Deep Learning, Artificial Intelligence, Machine Learning, Markov Chain, Q-Learning Algorithm},
	file = {Full Text PDF:C\:\\Users\\sande\\Zotero\\storage\\DLYCHXI5\\Ris-Ala - 2023 - Fundamentals of Reinforcement Learning.pdf:application/pdf},
}

@book{sewak_deep_2019,
	address = {Singapore, SINGAPORE},
	title = {Deep {Reinforcement} {Learning}: {Frontiers} of {Artificial} {Intelligence}},
	isbn = {9789811382857},
	shorttitle = {Deep {Reinforcement} {Learning}},
	url = {http://ebookcentral.proquest.com/lib/hs-coburg/detail.action?docID=5802517},
	abstract = {This book starts by presenting the basics of reinforcement learning using highly intuitive and easy-to-understand examples and applications, and then introduces the cutting-edge research advances that make reinforcement learning capable of out-performing most state-of-art systems, and even humans in a number of applications. The book not only equips readers with an understanding of multiple advanced and innovative algorithms, but also prepares them to implement systems such as those created by Google Deep Mind in actual code. This book is intended for readers who want to both understand and apply advanced concepts in a field that combines the best of two worlds - deep learning and reinforcement learning - to tap the potential of 'advanced artificial intelligence' for creating real-world applications and game-winning algorithms.},
	urldate = {2023-10-25},
	publisher = {Springer Singapore Pte. Limited},
	author = {Sewak, Mohit},
	year = {2019},
	keywords = {Reinforcement learning.},
	file = {ProQuest Ebook Snapshot:C\:\\Users\\sande\\Zotero\\storage\\AYQ9I97E\\detail.html:text/html},
}

@misc{noauthor_gymnasium_nodate,
	title = {Gymnasium {Documentation}},
	url = {https://gymnasium.farama.org/index.html},
	abstract = {A standard API for reinforcement learning and a diverse set of reference environments (formerly Gym)},
	language = {en},
	urldate = {2023-10-27},
	note = {(Zugriff am: 23.11.2023)
},
	file = {Snapshot:C\:\\Users\\sande\\Zotero\\storage\\K8MFMXLE\\gymnasium.farama.org.html:text/html},
}

@misc{noauthor_stable-baselines3_nodate,
	title = {Stable-{Baselines3} {Docs} - {Reliable} {Reinforcement} {Learning} {Implementations} — {Stable} {Baselines3} 2.2.0a8 documentation},
	url = {https://stable-baselines3.readthedocs.io/en/master/index.html},
	urldate = {2023-10-27},
	note = {(Zugriff am: 23.11.2023)
},
	file = {Stable-Baselines3 Docs - Reliable Reinforcement Learning Implementations — Stable Baselines3 2.2.0a8 documentation:C\:\\Users\\sande\\Zotero\\storage\\SN54B3KB\\index.html:text/html},
}

@article{ran_stable-baselines3_nodate,
	title = {Stable-{Baselines3}: {Reliable} {Reinforcement} {Learning} {Implementations}},
	abstract = {Stable-Baselines3 provides open-source implementations of deep reinforcement learning (RL) algorithms in Python. The implementations have been benchmarked against reference codebases, and automated unit tests cover 95\% of the code. The algorithms follow a consistent interface and are accompanied by extensive documentation, making it simple to train and compare diﬀerent RL algorithms. Our documentation, examples, and source-code are available at https://github.com/DLR-RM/stable-baselines3.},
	language = {en},
	author = {Raﬃn, Antonin and Hill, Ashley and Gleave, Adam and Kanervisto, Anssi and Ernestus, Maximilian and Dormann, Noah},
	file = {Raﬃn et al. - Stable-Baselines3 Reliable Reinforcement Learning.pdf:C\:\\Users\\sande\\Zotero\\storage\\VCVVJFF8\\Raﬃn et al. - Stable-Baselines3 Reliable Reinforcement Learning.pdf:application/pdf},
}

@misc{noauthor_matplotlib_nodate,
	title = {Matplotlib — {Visualization} with {Python}},
	url = {https://matplotlib.org/},
	urldate = {2023-10-29},
	note = {(Zugriff am: 23.11.2023)
},
	file = {Matplotlib — Visualization with Python:C\:\\Users\\sande\\Zotero\\storage\\SLRQVD9U\\matplotlib.org.html:text/html},
}

@misc{noauthor_ganz_2022,
	title = {Ganz schön clever - {Test}, {Bewertung}, {Regeln} \& {Strategie}},
	url = {https://spielenerds.de/ganz-schoen-clever/},
	abstract = {Das Würfelspiel „Ganz schön clever“ erklärt und von uns bewertet: Zubehör und Aufbau, sowie Spielregeln inklusive unserer Strategie.},
	language = {de-DE},
	urldate = {2023-10-30},
	month = jun,
	year = {2022},
	note = {Section: Brettspiel-Tests},
	annote = {(Zugriff: 19.11.2023)
},
	file = {Snapshot:C\:\\Users\\sande\\Zotero\\storage\\G5QN9PUZ\\ganz-schoen-clever.html:text/html},
}

@misc{noauthor_maschinelles_2023,
	title = {Maschinelles {Lernen} - {Weltweit} {\textbar} {Statista} {Marktprognose}},
	url = {https://de.statista.com/outlook/tmo/kuenstliche-intelligenz/maschinelles-lernen/weltweit},
	abstract = {Der Maschinelles-Lernen-Markt Weltweit erreicht ein jährliches Umsatzwachstum von 19,12\% (2023-2030), welches einem Marktvolumen von 507,50Mrd. € in 2030 entspricht.},
	language = {de},
	urldate = {2023-11-19},
	journal = {Statista},
	month = nov,
	year = {2023},
	note = {(Zugriff am: 23.11.2023)
},
	file = {Snapshot:C\:\\Users\\sande\\Zotero\\storage\\8SQZIRY3\\weltweit.html:text/html},
}

@misc{tagesschaude_chatgpt_nodate,
	title = {{ChatGPT} wächst rasant und startet {Bezahlversion}},
	url = {https://www.tagesschau.de/wirtschaft/digitales/chatgpt-wachstum-bezahlangebot-abo-101.html},
	abstract = {Mittlerweile greifen bereits 100 Millionen Menschen im Monat auf den umstrittenen Text-Roboter ChatGPT zu. Angesichts des rasanten Wachstums führt die Entwicklerfirma nun eine Bezahlversion ein.},
	language = {de},
	urldate = {2023-11-19},
	journal = {tagesschau.de},
	author = {tagesschau.de},
	note = {(Zugriff am: 23.11.2023)
},
	file = {Snapshot:C\:\\Users\\sande\\Zotero\\storage\\GTGUUVEB\\chatgpt-wachstum-bezahlangebot-abo-101.html:text/html},
}

@misc{noauthor_kunstliche_nodate,
	title = {Künstliche {Intelligenz} - {Weltweit} {\textbar} {Statista} {Marktprognose}},
	url = {https://de.statista.com/outlook/tmo/kuenstliche-intelligenz/weltweit},
	abstract = {Der Künstliche-Intelligenz-Markt Weltweit erreicht ein jährliches Umsatzwachstum von 17,68\% (2023-2030), welches einem Marktvolumen von 709,90Mrd. € in 2030 entspricht.},
	language = {de},
	urldate = {2023-11-19},
	journal = {Statista},
	note = {(Zugriff am: 23.11.2023)
},
	file = {Snapshot:C\:\\Users\\sande\\Zotero\\storage\\D5CW9N9W\\weltweit.html:text/html},
}

@misc{noauthor_kunstliche_2023,
	title = {Künstliche {Intelligenz} in {Videospielen}},
	url = {https://www.doag.org/de/home/news/kuenstliche-intelligenz-in-videospielen/},
	abstract = {KI ist in der Videospielbranche auf unterschiedliche Arten bereits fest integriert und wird die Zukunft des Gaming revolutionieren.},
	language = {de},
	urldate = {2023-11-19},
	author = {Rissmann, Moritz},
	note = {(Zugriff am: 23.11.2023)
},
	file = {Snapshot:C\:\\Users\\sande\\Zotero\\storage\\IK3SUCHW\\kuenstliche-intelligenz-in-videospielen.html:text/html},
}

@article{schmidt-hieber_nonparametric_2020,
	title = {Nonparametric regression using deep neural networks with {ReLU} activation function},
	volume = {48},
	issn = {0090-5364, 2168-8966},
	url = {https://projecteuclid.org/journals/annals-of-statistics/volume-48/issue-4/Nonparametric-regression-using-deep-neural-networks-with-ReLU-activation-function/10.1214/19-AOS1875.full},
	doi = {10.1214/19-AOS1875},
	abstract = {Consider the multivariate nonparametric regression model. It is shown that estimators based on sparsely connected deep neural networks with ReLU activation function and properly chosen network architecture achieve the minimax rates of convergence (up to \${\textbackslash}log n\$-factors) under a general composition assumption on the regression function. The framework includes many well-studied structural constraints such as (generalized) additive models. While there is a lot of flexibility in the network architecture, the tuning parameter is the sparsity of the network. Specifically, we consider large networks with number of potential network parameters exceeding the sample size. The analysis gives some insights into why multilayer feedforward neural networks perform well in practice. Interestingly, for ReLU activation function the depth (number of layers) of the neural network architectures plays an important role, and our theory suggests that for nonparametric regression, scaling the network depth with the sample size is natural. It is also shown that under the composition assumption wavelet estimators can only achieve suboptimal rates.},
	number = {4},
	urldate = {2023-11-20},
	journal = {The Annals of Statistics},
	author = {Schmidt-Hieber, Johannes},
	month = aug,
	year = {2020},
	note = {Publisher: Institute of Mathematical Statistics},
	keywords = {62G08, Additive models, minimax estimation risk, multilayer neural networks, Nonparametric regression, ReLU activation function, Wavelets},
	pages = {1875--1897},
	file = {Full Text PDF:C\:\\Users\\sande\\Zotero\\storage\\8WC3V7BX\\Schmidt-Hieber - 2020 - Nonparametric regression using deep neural network.pdf:application/pdf},
}

@article{noauthor_49340_ganz_schoen_clever_anleitung_final9_nodate,
	title = {49340\_Ganz\_schoen\_Clever\_ANLEITUNG\_FINAL9},
	language = {de},
	file = {49340_Ganz_schoen_Clever_ANLEITUNG_FINAL9.pdf:C\:\\Users\\sande\\Zotero\\storage\\IETIDZXC\\49340_Ganz_schoen_Clever_ANLEITUNG_FINAL9.pdf:application/pdf},
}

@misc{schmidtspiele_ganzschonclever,
  author = {{Schmidt Spiele}},
  title = {Ganz schön clever [Board game]},
  year = {2018},
  publisher = {Schmidt Spiele}
}

@Article{Hunter:2007,
  Author    = {Hunter, J. D.},
  Title     = {Matplotlib: A 2D graphics environment},
  Journal   = {Computing in Science \& Engineering},
  Volume    = {9},
  Number    = {3},
  Pages     = {90--95},
  abstract  = {Matplotlib is a 2D graphics package used for Python for
  application development, interactive scripting, and publication-quality
  image generation across user interfaces and operating systems.},
  publisher = {IEEE COMPUTER SOC},
  doi       = {10.1109/MCSE.2007.55},
  year      = 2007
}

@misc{towers_gymnasium_2023,
        title = {Gymnasium},
        url = {https://zenodo.org/record/8127025},
        abstract = {An API standard for single-agent reinforcement learning environments, with popular reference environments and related utilities (formerly Gym)},
        urldate = {2023-07-08},
        publisher = {Zenodo},
        author = {Towers, Mark and Terry, Jordan K. and Kwiatkowski, Ariel and Balis, John U. and Cola, Gianluca de and Deleu, Tristan and Goulão, Manuel and Kallinteris, Andreas and KG, Arjun and Krimmel, Markus and Perez-Vicente, Rodrigo and Pierré, Andrea and Schulhoff, Sander and Tai, Jun Jet and Shen, Andrew Tan Jin and Younis, Omar G.},
        month = mar,
        year = {2023},
        doi = {10.5281/zenodo.8127026},
}

@misc{statista_aiworldwide,
  author = {{Statista}},
  title = {Künstliche Intelligenz - Weltweit},
  year = {2023},
  howpublished = {\url{https://de.statista.com/outlook/tmo/kuenstliche-intelligenz/weltweit#marktgroesse}},
  note = {(Zugriff am: 23.11.2023)
}

@article{stable-baselines3,
  author  = {Antonin Raffin and Ashley Hill and Adam Gleave and Anssi Kanervisto and Maximilian Ernestus and Noah Dormann},
  title   = {Stable-Baselines3: Reliable Reinforcement Learning Implementations},
  journal = {Journal of Machine Learning Research},
  year    = {2021},
  volume  = {22},
  number  = {268},
  pages   = {1-8},
  url     = {http://jmlr.org/papers/v22/20-1364.html}
}


@book{millington_ai_2019,
	address = {Boca Raton},
	edition = {3},
	title = {{AI} for {Games}, {Third} {Edition}},
	isbn = {978-1-351-05330-3},
	abstract = {AI is an integral part of every video game. This book helps professionals keep up with the constantly evolving technological advances in the fast growing game industry and equips students with up-to-date information they need to jumpstart their careers. This revised and updated Third Edition includes new techniques, algorithms, data structures and representations needed to create powerful AI in games. 
Key Features
A comprehensive professional tutorial and reference to implement true AI in games
Includes new exercises so readers can test their comprehension and understanding of the concepts and practices presented
Revised and updated to cover new techniques and advances in AI
Walks the reader through the entire game AI development process},
	publisher = {CRC Press},
	author = {Millington, Ian},
	month = mar,
	year = {2019},
	doi = {10.1201/9781351053303},
}
