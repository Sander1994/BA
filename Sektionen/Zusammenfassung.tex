\section{Zusammenfassung und Ausblick}
Ziel dieser Arbeit war es, eine Künstliche Intelligenz, für das Brettspiel \textit{"Ganz schön clever"}, zu entwickeln und den Entwicklungs- sowie Trainingsprozess zu evaluieren.
Diese Künstliche Intelligenz wurde erfolgreich entwickelt und kann das Brettspiel \textit{"Ganz schön clever"} gut spielen. Gut bedeutet, dass sie in der Lage ist im Durchschnitt eine hohe Punktezahl zu erzielen. Zunächst wurde dafür ein Prototyp entwickelt, welcher dann schrittweise erweitert wurde, um die gesamte Komplexität des Spiels zu erfassen und um es gut spielen zu können.

Das Brettspiel \textit{"Ganz schön clever"} ist ein Würfelspiel, welches eine hohe Komplexität aufweist. Diese kommt vor allem durch die vielen Aktionsmöglichkeiten des Spielers und die multiplen Zusammenhängen innerhalb des Belohnungssystems zustande. Außerdem weist es eine hohe Stochastizität auf, welche die Komplexität weiter erhöht.


Die Spielumgebung und die Künstliche Intelligenz mussten vollständig implementiert werden. Dies geschah mithilfe von Bibliotheken wie Stable Baselines 3 und Gymnasium. Aus zeitlichen Gründen wurde lediglich die Ein-Spieler-Variante des Spiels implementiert. Für die Implementierung der Künstlichen Intelligenz wurde Deep Reinforcement Learning verwendet. Das neuronale Netz der Künstlichen Intelligenz ist ein Multilayer Perceptron mit sieben Schichten mit jeweils 1024 Neuronen, die eine ReLU-Aktivierungsfunktion verwenden.

Während der Implementierungsphase kam es zunächst zu einem Problem, bei dem die Künstliche Intelligenz es nur schwer selbstständig schaffte, gültige Aktionen zu wählen, welche nicht zum Abbruch des Spiels geführt haben. Das Vorgehen, bei dem das Spiel nach Wahl einer ungültigen Aktion abgebrochen wurde, wurde nach einigen Tagen verworfen, da es der Künstlichen Intelligenz das Lernen erschwerte, weil die meisten Spiele bereits nach wenigen Schritten endeten und die Künstliche Intelligenz so wenig relevante Daten sammeln konnte. Außerdem war die Bewertung der Performanz ebenfalls, durch die vielen Spielabbrüche, erschwert. Daraufhin wurde zunächst ein Verfahren implementiert, bei dem das Spiel bei ungültigen Aktionen nicht sofort abgebrochen, sondern negativ belohnt wurde. Diese Vorgehen stellte sich als gut geeignet heraus, wurde aber schnell von einem Vorgehen, welches eine Aktionsmaske verwendet abgelöst. Im folgenden wurde eine Aktionsmaske implementiert, welche gewährleistet, dass nur gültige Aktionen gewählt werden können. Somit musste die Künstliche Intelligenz nicht mehr selbstständig lernen, welche Aktionen gültig sind. Die Performanz stieg mit diesem Vorgehen von vorher durchschnittlich ungefähr 60 Prozent der Maximalpunktzahl auf 75 Prozent.

Zudem ergaben sich Schwierigkeiten bei der Erweiterung des Runden-Systems. Fast die gesamte Spielumgebung musste, an das neue Runden-System, angepasst werden. Dieser Aufwand wäre voraussichtlich deutlich geringer ausgefallen, wenn das Runden-System von Anfang an vollständig implementiert worden wäre.

Das finale Training der Künstlichen Intelligenz erfolgte in von drei Phasen. Zunächst wurde die KI in 2.220.000 Trainingsschritten vortrainiert. Anschließend wurde sie in 1.110.000 Trainingsschritten, mit einem verringerten Entropie-Koeffizienten, was einer geringeren Exploration entspricht, nachtrainiert, um das gelernte Verhalten zu verfestigen. Dieses Training erfolgte daraufhin mit der doppelten Zeit weitere zwei Male. Das Ergebnis des Trainings war eine Künstliche Intelligenz, welche durchschnittlich 208 Punkte im Spiel erzielt. Im Vergleich dazu erzielten menschliche Spieler in einem Test im Durchschnitt lediglich 160 Punkte. Für die durchschnittlichen Punktezahlen, wurden die erreichten Punkte einer abgeschlossenen Spielumgebung abgespeichert, anschließend aufaddiert und durch ihre Anzahl geteilt. Die Standardabweichung lag im letzten Test bei 31 und der Median bei 214. Einmalig erzielte die Künstliche Intelligenz 282 Punkte, was laut der offiziellen Punkteskala von Schmidt Spiele dem höchsten Level an Performanz entspricht \cite{noauthor_49340_ganz_schoen_clever_anleitung_final9_nodate}.

Besonders hilfreich war es, einen Prototypen zu bauen und diesen anschließend schrittweise auszubauen. Dies hat dabei geholfen leichter einen Überblick über die wichtigsten Aspekte des Vorhabens zu gewinnen. 

Die Implementierung der Künstlichen Intelligenz selbst gestaltete sich dank Bibliotheken wie Gymnasium und Stable Baselines vergleichsweise einfach, brachte aber dennoch eine Vielzahl interessanter und nützlicher Erkenntnisse mit sich. Besonders hervorzuheben ist dabei die Anpassung von Hyperparametern, welche zum Teil zu sehr unterschiedlichen Ergebnissen geführt hat. 

Der aufwändigste Teil des Projektes war die Implementierung des Spielumgebung selbst. Das Spiel hat viele kleine Interaktionen, welche zum Teil ineinander verschachtelt sind und es gestaltete sich zum Teil schwierig alle Zusammenhänge zu überschauen und zu gewährleisten, dass Änderungen an einer Funktion andere nicht negativ beeinflusst. Es sind auch vielerlei Bugs aufgetreten, die gefunden und behoben werden mussten. Der gravierendste Fehler war es, das Runden-System nicht von vornherein zu implementieren, sondern es später einzufügen, als die meisten anderen Aspekte des Spiels bereits implementiert waren. Dies führte dazu, dass viele Aspekte der Spielumgebung neu überdacht und überarbeitet werden mussten. Für die Zukunft bleibt zu sagen, dass besonders am Anfang ein Fokus auf alle grundlegenden Aspekte der Problemstellung von Vorteil ist. Sobald das Projekt mit all seinen Grundkomponenten lauffähig ist, sollte es um weniger grundlegende Aspekte erweitert werden. Der Einfluss einer Änderung des Runden-Systems wurde unterschätzt.\\

Für die Weiterarbeit am Projekt bietet sich die Implementierung einer grafischen Visualisierung des Lern- oder Vorhersageprozesses an. Außerdem lässt sich das Modell sicherlich mithilfe anderer Algorithmen, Trainingsverfahren oder Hyperparameter weiter optimieren. Was im Rahmen der Arbeit ebenfalls nur bedingt erfolgte, ist eine Analyse der Spielstrategien von Modellen und wie sich unterschiedliche Strategien auf die Performance auswirken. Zwar wurden Variablen hinzugefügt, welche messen, wie oft Kästchen in bestimmten Feldern ausgefüllt wurden, allerdings lässt sich hier noch viel mehr machen. Ebenfalls wäre es sinnvoll, Tests für das Projekt zu implementieren, um sicherzustellen, dass alle Aspekte der Umgebung wie vorhergesehen funktionieren und zusammenarbeiten. Zwar erfolgten Tests durch die Auswertung von Umgebungsvariablen und Print-Statements, aber es fehlt dem Projekt eine fundierte Umsetzung professioneller Testverfahren.